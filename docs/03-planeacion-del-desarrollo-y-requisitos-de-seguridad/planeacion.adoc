== Planeación del desarrollo y requisitos de seguridad

La planeación constituye la fase inicial del ciclo de vida del desarrollo de una API. En esta etapa, se establece el propósito de la API, así como los casos de uso y los recursos necesarios para su construcción. Se realiza la definición de los requisitos operativos, de negocio y de seguridad, y se identifican los equipos encargados de guiar la API a lo largo de las fases posteriores (Postman, 2023).

Según Swagger (2022), una planeación adecuada comprende el mapeo de recursos, operaciones y escenarios de negocio antes de la implementación. Por su parte, Akamai (2022) resalta la importancia de incluir la estrategia de la API, las decisiones arquitectónicas de alto nivel y la creación de contratos que describan el comportamiento esperado de la misma.

Esta etapa abarca los requisitos tanto funcionales (las funcionalidades que la API debe ofrecer) como los no funcionales (atributos de calidad que determinan su comportamiento). En este último grupo, la seguridad desempeña un papel crítico, al requerir la identificación de posibles riesgos, el establecimiento de mecanismos de autenticación y autorización, el cumplimiento normativo, la selección de herramientas y demás prácticas que acompañan el ciclo de desarrollo.

Las prácticas reportadas en la literatura para esta fase se presentan en la siguiente tabla:


[cols="1,2,1", options="header"]
|===
|Nombre |Descripción |Referencia

|Análisis del inventario
|Revisión de las APIs existentes en la organización con el objetivo de verificar el cumplimiento de los requerimientos del nuevo proyecto. Esta práctica permite evitar el desarrollo de funcionalidades redundantes y minimizar la complejidad innecesaria dentro del ecosistema de APIs.
|Guba, 2025

|Análisis de público objetivo
|Identificación de los usuarios previstos de la API y de los problemas específicos que se pretende resolver. Este análisis facilita la definición de casos de uso claros y asegura la alineación entre los objetivos técnicos y los objetivos de negocio.
|Guba, 2025

|Viabilidad técnica
|Evaluación de los recursos, tecnologías e infraestructura necesarios para el desarrollo, implementación, mantenimiento y operación a largo plazo de la API.
|Guba, 2025

|Definir políticas y responsabilidades
|Establecimiento de lineamientos que regulen la seguridad, gobernanza y cumplimiento normativo en el diseño y uso de la API, incluyendo la asignación de responsabilidades a los distintos actores involucrados en su ciclo de vida.
|Guba, 2025

|Definición de requisites
|Documentación clara de los casos de uso y de los usuarios previstos de la API, asegurando que esta incorpore únicamente las funcionalidades necesarias y evitando tanto la sobrecarga como omisiones críticas.
|(Varga, Pereira de Andrade, de Morais, Bomfim, & Avancini Fraga, 2025)

|Definición inicial de requisitos y preparación del entorno de trabajo
|Determinación de los requisitos operativos, de negocio y de seguridad de la API, así como identificación de los integrantes del equipo responsables de su desarrollo a lo largo de las fases del ciclo de vida. Esta práctica incluye la recomendación de establecer un entorno de colaboración desde el inicio, como un espacio de trabajo dedicado y un repositorio en GitHub conectado a un pipeline de integración continua (CI).
|Postman (s.f)
|===

=== Evaluación organizacional y su relación con la seguridad

La seguridad de una API no depende exclusivamente de mecanismos técnicos, sino también de la cultura organizacional que sustenta su desarrollo y operación. La cultura de seguridad se entiende como el conjunto de valores que determinan la forma en que los individuos perciben y abordan la seguridad dentro de la organización. Esta cultura se ve influida por las metas institucionales, la estructura organizativa, las políticas, los procesos y el liderazgo, así como por las relaciones con socios, proveedores y otros actores externos (NCSC, 2021).

La cultura de ciberseguridad abarca asimismo las actitudes, conocimientos, normas y valores de los empleados en relación con la seguridad. Su efectividad no depende únicamente de políticas o procesos, sino de la alineación entre factores organizacionales (liderazgo, procesos, normas) y factores individuales (actitudes, conocimientos, comportamientos). La inversión en una cultura sólida fortalece la seguridad técnica de las APIs, genera confianza digital, mejora la reputación organizacional y promueve la adopción de comportamientos seguros en el trabajo cotidiano (PA Consulting, s.f.).

En entornos con una cultura de seguridad consolidada, los equipos perciben la seguridad como un esfuerzo colectivo y colaborativo que respalda las actividades diarias. Según el NCSC (2021), los principales beneficios incluyen:

* Mayor propensión de los empleados a identificar problemas y proponer mejoras, fortaleciendo la resiliencia.
* Facilita la comunicación abierta sobre incidentes sin temor a represalias.
* Mejora del bienestar y la retención del personal, al fomentar la inclusión y explicar claramente el propósito de las medidas de seguridad.

Para consolidar esta cultura, se recomienda complementar las prácticas organizacionales con certificaciones reconocidas, tales como ISO 27001 y Cyber Essentials, que establecen estándares, procesos y políticas destinados a incrementar la resiliencia cibernética de la organización.

Un enfoque complementario es la estrategia de seguridad Zero Trust, basada en la premisa de que ninguna persona o dispositivo, tanto dentro como fuera de la red organizacional, debe considerarse de confianza de manera automática. Este modelo se fundamenta en tres principios esenciales (Akamai, s.f.):

* Verificación de la confianza de todas las entidades.
* Aplicación del principio de privilegios mínimos.
* Implementación de una supervisión continua de la seguridad.

Estas prácticas organizacionales y modelos, como Zero Trust, resultan especialmente relevantes en el diseño y operación de APIs REST, dado que la exposición directa a internet incrementa la superficie de ataque y exige la alineación entre los aspectos técnicos y humanos dentro de una misma estrategia de seguridad.

=== Identificación de amenazas y riesgos

La identificación de amenazas y riesgos constituye una etapa crítica en el desarrollo seguro de APIs. Una amenaza se define como un evento o conjunto de circunstancias que puede comprometer los objetivos de seguridad de la API. Por ejemplo, un atacante que obtiene nombres y direcciones de la base de datos de clientes representa una amenaza para la confidencialidad de la información (Madden, 2020).

Las APIs se enfrentan a una amplia variedad de amenazas de seguridad, que incluyen ataques deliberados y fugas de datos involuntarias. Los usuarios no autorizados pueden explotar vulnerabilidades para acceder a datos confidenciales, interrumpir servicios o secuestrar sistemas. 

Entre las amenazas más frecuentes se encuentran los ataques de inyección, los ataques de tipo "man-in-the-middle" (MITM) y los ataques de denegación de servicio distribuido (DDoS), diseñados para sobrecargar una API con tráfico malicioso (Akamai, s.f.). Aunque el tipo y la frecuencia de las amenazas pueden variar según el modelo de API, los ataques más comunes deben considerarse para cualquier API que se diseñe o utilice (Chapple & Seidl, 2022).

La identificación de amenazas implica determinar los riesgos potenciales mediante herramientas y estrategias como listas de verificación, trazabilidad, análisis de puntos de entrada y evaluación de vulnerabilidades (ScienceDirect, s.f.). Este proceso permite relacionar los componentes del sistema con los elementos de la amenaza para su posterior validación y verificación.

Además de la identificación, la búsqueda activa de amenazas, conocida como threat hunting, consiste en la detección proactiva de amenazas desconocidas o previamente no detectadas dentro de la red de una organización. A diferencia del monitoreo de seguridad tradicional, que se enfoca en la detección y respuesta a amenazas conocidas mediante herramientas automatizadas, la búsqueda de amenazas persigue anticiparse a riesgos emergentes, permitiendo mitigarlos antes de que puedan generar daños significativos (Akamai, s.f.).

Por lo tanto, la labor del diseñador de una API no se limita a garantizar el cumplimiento de sus funciones requeridas, sino que también incluye una vigilancia constante del panorama de seguridad, con el objetivo de prevenir y mitigar posibles amenazas que puedan comprometer la integridad del sistema (Lalonchera, 2025).

=== Referencias normativas y técnicas de seguridad para API

Los estándares de seguridad de API constituyen marcos y pautas diseñados para garantizar la protección de las APIs frente a posibles amenazas y vulnerabilidades. Estos estándares permiten a las organizaciones implementar medidas de seguridad consistentes y efectivas (PubNub, 2024).

Estos marcos de seguridad abarcan diversos aspectos, incluyendo autenticación, autorización, cifrado de datos y gestión de sesiones. Su aplicación asegura que la comunicación a través de la API se adhiera a principios de seguridad, previniendo accesos no autorizados y posibles violaciones de datos (Pynt, 2024).

Por otra parte, los protocolos de API definen los mecanismos de transmisión y protección de datos en la red. Establecen un lenguaje común y procedimientos que deben seguir tanto el emisor como el receptor, garantizando un intercambio seguro de información. Esto incluye el manejo seguro de tokens, cifrado de mensajes y validación de credenciales de identidad (Pynt, 2024).

A continuación, se describen algunos de los principales estándares utilizados en la industria. Se aclara que la lista no es exhaustiva, y la selección del estándar adecuado dependerá del contexto, las necesidades de la aplicación y los requerimientos de la organización.

==== OAuth 2.0

OAuth 2.0 es uno de los marcos de autorización más utilizados para APIs web. Su objetivo principal es permitir que un usuario otorgue a una aplicación de terceros acceso limitado a sus recursos, sin necesidad de compartir sus credenciales. Este modelo se ha convertido en un estándar en la autorización de APIs y es ampliamente adoptado en entornos web, móviles y en la nube (Varga et al., 2025).

El funcionamiento básico de OAuth 2.0 consiste en que el usuario se autentica con un proveedor de identidad (por ejemplo, Google o Facebook) y concede permisos a la aplicación de terceros. Posteriormente, la aplicación obtiene un token de acceso, el cual se emplea para realizar solicitudes autorizadas a la API en nombre del usuario. Dicho token contiene scopes o alcances, que determinan el nivel de acceso permitido, como lectura o escritura sobre determinados recursos.

===== Consideraciones de seguridad

Al implementar OAuth 2.0, se deben tener en cuenta medidas de seguridad específicas para mitigar riesgos comunes asociados al manejo de tokens:

* Utilizar exclusivamente conexiones seguras (HTTPS) para la transmisión de tokens.
* Preferir tokens de corta duración acompañados de refresh tokens, a fin de reducir el riesgo en caso de robo de un token.
* Implementar mecanismos de revocación para invalidar tokens cuando sea necesario.

===== Ventajas

* Permite el acceso delegado sin necesidad de compartir credenciales del usuario.  
* Su amplia adopción promueve la estandarización en diversos servicios.  
* Facilita la integración entre aplicaciones heterogéneas (web, móviles y cloud).

===== Desventajas

* Requiere mecanismos seguros de almacenamiento y transmisión de tokens.  
* Introduce cierta complejidad en la gestión de tokens, especialmente con refresh tokens y su expiración.  
* Puede implicar sobrecarga en entornos con múltiples integraciones.

[TIP]
====
Se recomienda el uso de OAuth 2.0 en escenarios donde se requiera interacción con aplicaciones de terceros o integración con proveedores de identidad externos, así como en sistemas que manejen datos sensibles y deban delegar autorización sin exponer credenciales.  

Sin embargo, para aplicaciones internas o entornos con bajo riesgo de exposición, puede considerarse un mecanismo más simple, como autenticación mediante API keys o tokens firmados localmente.
====


==== JSON Web Token (JWT) 

Los JSON Web Tokens (JWT) constituyen un formato de token estandarizado por RFC, ampliamente utilizado en protocolos de autorización como OAuth 2.0. Un JWT contiene claims, que son declaraciones con valores asociados, y está estructurado y codificado según estándares que garantizan que el token no pueda ser modificado y que pueda cifrarse adicionalmente (Mastering API Architecture).

[TIP]
====
Este tipo de tokens resulta especialmente útil para la transferencia de información en entornos con restricciones de espacio, como los encabezados de autorización HTTP.
====

A continuación se presenta un ejemplo de un JWT que podría ser utilizado en una API web REST para autenticar a un usuario:

[source,json]
----
{
    "iss": "http://secure/identity-provider",
    "sub": "123e4567-e89b-12d3-a456-426614174000",
    "aud": "Servicio-Usuarios",
    "exp": 1735689600,
    "nbf": 1735686000,
    "iat": 1735686000,
    "jti": "abc12345-6789-4567-890a-bcdef1234567"
}
----

En este token, las claims incluidas son `iss`, `sub`, `aud`, `exp`, `nbf`, `iat` y `jti`. Estas son claims reservadas definidas en el RFC de JWT. Aunque no son obligatorias, proporcionan un conjunto mínimo de información útil para la autenticación y autorización.

* `iss` (Issuer): Autoridad que emite el token, normalmente un proveedor de identidad.  
* `sub` (Subject): Identificador único del sujeto al que representa el token, por ejemplo, un usuario o una aplicación.  
* `aud` (Audience): Destinatario o servicio para el cual el token está destinado.  
* `exp` (Expiration time): Fecha y hora de expiración del token.  
* `nbf` (Not before): Momento a partir del cual el token es válido.  
* `iat` (Issued at): Fecha y hora de emisión del token.  
* `jti` (JWT ID): Identificador único del token, útil para evitar la reutilización.

===== Ventajas

* La autenticación sin estado (stateless) escala adecuadamente en sistemas distribuidos.  
* No requiere almacenar información de sesión en el servidor.  
* Permite control granular de los derechos de acceso mediante las claims del token.  
* Facilita la interoperabilidad entre servicios y aplicaciones heterogéneas.

===== Desventajas

* Si un token es robado, puede ser utilizado para suplantar al usuario.  
* La gestión de la expiración de tokens y los ciclos de renovación añade complejidad a la aplicación, tanto en frontend como en backend.  
* Se requiere cuidado en la implementación de la validación y revocación de tokens para evitar vulnerabilidades.

==== OpenID Connect (OIDC)

OAuth 2.0 proporciona un mecanismo para que el cliente acceda a APIs utilizando autenticación y autorización. Sin embargo, un requerimiento común es que el cliente también pueda conocer la identidad del propietario del recurso. Este es el propósito de OpenID Connect (OIDC): añadir una capa de identidad sobre OAuth 2.0.  

OIDC amplía el servidor de autorización OAuth 2.0 para que actúe también como proveedor de identidad, entregando al cliente un *ID token* (un JWT con claims sobre el usuario) cuando se utiliza el scope especial `openid`. Además, se pueden incluir scopes adicionales como `profile`, `email`, `address` o `phone`, permitiendo obtener información más completa sobre el usuario (Gough, Bryant & Auburn, 2022).

Los flujos definidos por OIDC son tres: Authorization Code Flow, Implicit Flow y Hybrid Flow. El recomendado es el Authorization Code Flow junto con PKCE, ya que ofrece mayor seguridad.

[TIP]
====
OIDC y OAuth 2.0 no son lo mismo. OAuth 2.0 gestiona autorización para acceder a recursos, mientras que OIDC proporciona información de identidad del usuario. Ambos son complementarios.
====

[WARNING]
====
Nunca se deben usar los *ID tokens* como si fueran *access tokens*. Los *ID tokens* son de mayor duración y están diseñados únicamente para proporcionar información de identidad, no para acceder a recursos.
====

===== Ventajas

* Añade una capa de identidad estándar sobre OAuth 2.0.  
* Permite obtener información verificada del usuario mediante scopes adicionales.  
* Compatible con JWT, lo que facilita la interoperabilidad.  
* Amplia adopción en entornos web y móviles.  

===== Desventajas

* Introduce complejidad adicional respecto a OAuth 2.0 puro.  
* Requiere que el proveedor de identidad soporte explícitamente OIDC.  
* Una implementación incorrecta puede dar lugar a filtración de datos sensibles.  


==== SAML 2.0

En entornos empresariales es común el uso de SAML 2.0 (Security Assertion Markup Language), un estándar abierto que transfiere *assertions* de identidad. Es ampliamente utilizado en escenarios de *single sign-on (SSO)*, permitiendo que empleados accedan a aplicaciones externas mediante sus credenciales corporativas.  

Aunque SAML no está diseñado para usarse directamente en APIs REST, existe una extensión llamada *SAML 2.0 Profile for OAuth 2.0 Client Authentication and Authorization Grants*, la cual permite a un cliente solicitar un *access token* usando SAML, siempre que el servidor de autorización tenga soporte para esta funcionalidad (Gough, Bryant & Auburn, 2022).  

===== Ventajas

* Muy utilizado en entornos corporativos para SSO.  
* Permite federación de identidad entre organizaciones.  
* Estándar maduro y con amplio soporte en sistemas empresariales.  

===== Desventajas

* No está alineado con el diseño de APIs REST modernas.  
* Mayor complejidad en comparación con OIDC.  
* Requiere integración específica con servidores que soporten el perfil SAML-OAuth2.  

[TIP]
====
SAML sigue siendo relevante en migraciones hacia OAuth 2.0 y OIDC, especialmente en organizaciones con infraestructuras legadas o en procesos de federación de identidad.
====


==== Transport Layer Security (TLS)

Transport Layer Security (TLS) es un protocolo que opera sobre TCP/IP y proporciona funciones de seguridad esenciales para permitir la comunicación segura entre un cliente y un servidor. TLS garantiza la confidencialidad, integridad y autenticidad de los datos transmitidos, protegiendo las comunicaciones frente a ataques de tipo man-in-the-middle (MITM) (Madden, s.f.; Chun et al., 2024; Brikman, 2025).

TLS se implementa mediante un handshake inicial en el que el cliente autentica al servidor, garantizando que se conecta a la entidad correcta y no a un atacante. Durante este proceso, se negocian las versiones del protocolo y los algoritmos criptográficos a utilizar, así como las claves de cifrado que se emplearán para el resto de la sesión. La información transmitida posteriormente se cifra y autentica utilizando estas claves, asegurando que no pueda ser leída ni modificada por terceros (Madden, s.f.; Brikman, 2025).

TLS es ampliamente utilizado en protocolos de API basados en HTTP, incluyendo REST y SOAP, para cifrar la comunicación entre clientes y servidores. En algunos casos, además del cifrado de canal que proporciona TLS, puede ser necesario aplicar cifrado adicional a nivel de payload para proteger datos sensibles de manera más granular (Chun et al., 2024).

===== Ventajas

* Garantiza confidencialidad de los datos transmitidos mediante cifrado de canal.  
* Asegura la integridad y autenticidad de los mensajes, previniendo modificaciones y suplantación de identidad.  
* Protege contra ataques de intermediario (*MITM*).  
* Amplia compatibilidad con protocolos web y de API modernos.  
* Puede implementarse con autenticación mutua (*mTLS*) en arquitecturas de microservicios para validar ambos extremos de la comunicación.

===== Desventajas

* Requiere configuración cuidadosa de versiones de protocolo y algoritmos criptográficos.  
* Puede generar sobrecarga en términos de rendimiento, especialmente con cifrado fuerte o en entornos de alto tráfico.  
* La gestión de certificados y autoridades de certificación (CAs) añade complejidad administrativa.  
* Implementaciones incorrectas o uso de versiones obsoletas pueden introducir vulnerabilidades.


==== PASETO

El estándar Platform-Agnostic Security Tokens (PASETO) surge como una alternativa moderna y más segura a JSON Web Tokens (JWT) dentro de los esquemas de autenticación basados en tokens. PASETO fue diseñado para evitar los errores comunes y vulnerabilidades derivados del uso de JSON Object Signing and Encryption (JOSE), ofreciendo un formato más predecible, seguro y menos propenso a configuraciones inseguras (Madden, 2020).  

A diferencia de JWT, que permite al desarrollador seleccionar entre una amplia variedad de algoritmos criptográficos, PASETO restringe esta elección y define un conjunto fijo de algoritmos por versión. La versión 1 utiliza algoritmos ampliamente adoptados como AES y RSA, mientras que la versión 2 emplea algoritmos modernos y más robustos, como Ed25519 para la firma digital y XChaCha20-Poly1305 para el cifrado autenticado. Este diseño elimina las posibilidades de que un atacante explote configuraciones débiles o confusas, incrementando la fiabilidad criptográfica del token (Madden, 2020).  

Asimismo, PASETO admite tanto cifrado simétrico autenticado como firma con clave pública, cubriendo los mismos casos de uso que JWT, pero con una arquitectura más estricta y segura. Los algoritmos y bibliotecas empleados son conocidos únicamente por el servidor emisor del token, lo que dificulta los intentos de falsificación o manipulación. Además, cada versión del protocolo establece su propio conjunto de reglas y algoritmos, promoviendo la interoperabilidad y la previsibilidad en la implementación (Nugraha, Kabetta, Buana & Hadiprakoso, 2023).  

En cuanto al desempeño, estudios comparativos han demostrado que JWT presenta una mejor eficiencia en tiempo de generación y tamaño de token; sin embargo, PASETO ofrece una resistencia significativamente superior frente a vulnerabilidades críticas. Según Nugraha et al. (2023), las pruebas de seguridad realizadas evidenciaron que JWT es susceptible a ataques como Broken User Authentication y explotación de encabezados, mientras que PASETO mostró solidez ante las principales vulnerabilidades documentadas en el OWASP API Security Top 10 (2019).

===== Ventajas

* Su diseño prioriza la seguridad desde la definición de sus algoritmos y versiones.  
* Define algoritmos criptográficos fijos por versión, eliminando opciones inseguras.  
* Resistente frente a vulnerabilidades comunes en JWT (por ejemplo, manipulación del encabezado de algoritmo).  
* Ofrece autenticación basada en cifrado simétrico o en firma asimétrica.  
* Proporciona mayor previsibilidad y control criptográfico.  

===== Desventajas

* Menor rendimiento en comparación con JWT en la generación y transferencia de tokens.  
* Tamaño de token superior, lo que puede impactar en entornos con restricciones de ancho de banda.  
* Adopción limitada y menor disponibilidad de bibliotecas en comparación con JWT.  

[TIP]
====
PASETO representa una evolución hacia mecanismos de autenticación más seguros en APIs RESTful. Si bien su rendimiento es inferior, su diseño restringido y predecible lo convierte en una opción recomendable para sistemas que priorizan la seguridad sobre la eficiencia, especialmente en el manejo de datos sensibles o en arquitecturas distribuidas.
====

==== CORS

Cross-Origin Resource Sharing (CORS) es un estándar que permite que aplicaciones web realicen solicitudes a APIs alojadas en dominios distintos al de la aplicación cliente. Este mecanismo surge como extensión controlada de la política del mismo origen (Same-Origin Policy), la cual bloquea solicitudes entre dominios diferentes para proteger contra ataques como Cross-Site Request Forgery (CSRF). Lock, A. (2022). ASP.NET Core in Action (2nd ed.). Manning Publications.  

La política del mismo origen considera que dos recursos comparten origen únicamente si coinciden en esquema (HTTP o HTTPS), dominio y puerto. Por ejemplo:

* `http://tienda.com/home` y `http://tienda.com/assets/style.css` tienen el mismo origen.  
* `https://tienda.com` no comparte origen con `http://tienda.com` debido a la diferencia de esquema.  
* `http://api.tienda.com` no comparte origen con `http://tienda.com` por ser un subdominio distinto.  
* `http://tienda.com:8080` no comparte origen con `http://tienda.com` porque usan puertos diferentes.  

CORS funciona mediante encabezados HTTP especiales que el servidor devuelve para indicar qué orígenes están autorizados, qué métodos HTTP se permiten y si se pueden enviar credenciales (cookies o cabeceras de autorización). En algunos casos, el navegador realiza primero una solicitud preliminar (preflight request) usando el método OPTIONS para verificar que la solicitud real está permitida. Si el servidor responde con los encabezados correctos, se ejecuta la solicitud principal.  

Este estándar permite configurar políticas de CORS a nivel global para toda la aplicación o de manera selectiva por endpoint. Las políticas pueden definir qué dominios, métodos y cabeceras están permitidos, manteniendo la seguridad de la política del mismo origen al tiempo que habilitan la interoperabilidad entre aplicaciones y servicios en distintos dominios.  

===== Ventajas

* Habilita de forma controlada la comunicación entre dominios distintos.  
* Mantiene la protección de la política del mismo origen.  
* Permite configurar políticas específicas por dominio, método o endpoint.  

===== Desventajas

* Configuraciones inadecuadas pueden exponer la API a riesgos de seguridad.  
* Requiere comprender correctamente los encabezados y el flujo de CORS.  
* Puede añadir complejidad en la configuración de aplicaciones distribuidas.  

[TIP]
====
Es recomendable habilitar CORS únicamente cuando sea necesario, configurando políticas específicas y evitando permitir cualquier origen de manera global. Por ejemplo, solo permitir que `https://app.tienda.com` acceda a `http://api.tienda.com`.
====

==== Implementación de CORS en Python

A continuación se muestra cómo habilitar CORS en un API REST desarrollada con FastAPI:

[source,python]
----
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="Tienda API")

# Lista de dominios permitidos para acceder a la API
origins = [
    "https://app.tienda.com",
    "https://admin.tienda.com"
]

# Agregar el middleware de CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,  # solo los dominios especificados
    allow_credentials=True,  # permite enviar cookies o cabeceras de autorización
    allow_methods=["GET", "POST", "PUT", "DELETE"],  # métodos HTTP permitidos
    allow_headers=["Authorization", "Content-Type"],  # cabeceras permitidas
)
----

[TIP]
====
Evita habilitar CORS de forma global con `allow_origins=["*"]` en producción, ya que esto permite que cualquier dominio haga solicitudes a tu API, incrementando el riesgo de ataques.
====

==== ISO/IEC 27001: Information Security Management

ISO/IEC 27001 es un estándar internacionalmente reconocido para la gestión de la seguridad de la información. Proporciona un enfoque sistemático para administrar información sensible de la organización, garantizando que se mantenga segura. Esto incluye desde datos financieros, propiedad intelectual y detalles de empleados hasta información confiada por terceros (Edwards & Weaver, 2023).

El estándar establece la base para un *Information Security Management System (ISMS)*, exigiendo que la organización diseñe e implemente un conjunto coherente y completo de controles de seguridad de la información. Los controles no son prescriptivos, lo que permite a cada organización adaptarlos según sus necesidades y contexto. Entre los aspectos cubiertos se incluyen evaluación de riesgos, políticas de seguridad, gestión de activos, control de accesos y seguridad física y ambiental (Staveley, 2023).

ISO/IEC 27001 puede aplicarse a cualquier organización, independientemente de su tamaño o industria, aunque resulta especialmente relevante en sectores que manejan información altamente sensible, como instituciones financieras. Su implementación proporciona un marco estructurado para proteger la información, reducir riesgos y demostrar un compromiso con las mejores prácticas de seguridad.

===== Beneficios de aplicar ISO/IEC 27001 en APIs

* **Gestión integral de la seguridad:** Permite establecer un marco consistente para proteger las APIs y la información que manejan (Staveley, 2023).  
* **Flexibilidad:** Los controles pueden adaptarse a la complejidad de la organización y a las particularidades de sus servicios API (Edwards & Weaver, 2023).  
* **Reducción de riesgos:** Al incluir evaluaciones periódicas de riesgo y controles de seguridad, se disminuye la probabilidad de incidentes de seguridad (Staveley, 2023).  
* **Mejora continua:** El estándar promueve la revisión constante y la actualización de medidas de seguridad, manteniendo las APIs seguras frente a nuevas amenazas (Edwards & Weaver, 2023).  
* **Confianza y reputación:** Aplicar ISO/IEC 27001 demuestra a clientes y socios un enfoque profesional y estructurado en la protección de datos (Staveley, 2023).  

[TIP]
====
Al implementar APIs seguras dentro de un marco ISO/IEC 27001, las organizaciones no solo protegen la información, sino que también facilitan la interoperabilidad segura y el cumplimiento normativo, fortaleciendo la confianza de usuarios y socios comerciales.
====
==== NIST SP 800-228: Directrices para la protección de APIs en sistemas cloud-native

El NIST Special Publication 800-228 (_Guidelines for API Protection for Cloud-Native Systems_) establece lineamientos específicos para la protección y aseguramiento de APIs en entornos empresariales modernos. 
Este estándar reconoce que las APIs son el medio principal de comunicación e integración entre sistemas en arquitecturas nativas de la nube, por lo que su seguridad resulta esencial para la postura de seguridad general de las organizaciones (Chandramouli & Butcher, 2025).

El documento propone un modelo de protección integral del ciclo de vida de las APIs, basado en los principios de DevSecOps y el paradigma de Zero Trust, considerando controles tanto previos a la ejecución (pre-runtime) como durante la ejecución (runtime). 
Estos controles se clasifican en básicos y avanzados, lo que permite su adopción de forma incremental y basada en el riesgo, de acuerdo con la madurez de la organización.

Entre sus principales aportaciones destacan:

* Identificación de factores de riesgo y vulnerabilidades que pueden introducirse durante el desarrollo o despliegue de APIs.
* Controles y medidas de protección recomendadas que abarcan desde la fase de diseño hasta la ejecución de peticiones.
* Patrones de implementación con análisis de ventajas y desventajas, que orientan a los profesionales de seguridad en la selección de enfoques adecuados a su ecosistema tecnológico.
* Clasificación de APIs y su relación con las fases del ciclo DevSecOps, facilitando la integración de la seguridad como parte del desarrollo continuo.

Este estándar resulta relevante para las guías de diseño seguro de APIs REST, ya que ofrece un marco actualizado para mitigar vulnerabilidades desde la concepción y el diseño, reforzando la seguridad mediante controles expresados en términos de recursos (nombres) y operaciones (verbos), en coherencia con los principios REST.

==== Regulaciones de protección de datos y privacidad

Además de los estándares técnicos y normativos como ISO/IEC 27001 y NIST SP 800-228, existen marcos legales que complementan la seguridad de las APIs desde la perspectiva de la protección de datos personales y la privacidad. Estas regulaciones buscan garantizar que las organizaciones gestionen la información sensible de manera responsable, transparente y conforme a los derechos de los individuos.  

Entre las más relevantes se encuentran el Reglamento General de Protección de Datos (GDPR) en la Unión Europea, la California Consumer Privacy Act (CCPA) en Estados Unidos y la Personal Information Protection and Electronic Documents Act (PIPEDA) en Canadá. Todas ellas establecen obligaciones como obtener consentimiento para el tratamiento de datos, aplicar medidas técnicas de seguridad y permitir a los usuarios ejercer derechos sobre su información (Staveley, 2023).

===== GDPR: Reglamento General de Protección de Datos (Unión Europea)

El Reglamento General de Protección de Datos (GDPR) representa el marco más influyente en materia de privacidad a nivel mundial. Su objetivo es proteger los datos personales de los ciudadanos y residentes europeos, fortaleciendo sus derechos y unificando las regulaciones entre los Estados miembros.  

El GDPR establece principios fundamentales de transparencia, responsabilidad y minimización de datos, los cuales pueden integrarse de forma natural en el diseño y operación de APIs REST seguras.  
Entre sus disposiciones más destacadas se incluyen:

* **Derechos de los interesados:** acceso, rectificación, eliminación (*derecho al olvido*) y portabilidad de datos personales.  
* **Consentimiento informado:** las organizaciones deben obtener autorización clara y explícita antes de procesar datos personales.  
* **Seguridad y confidencialidad:** uso obligatorio de controles técnicos como cifrado, autenticación, control de accesos, auditorías y gestión de incidentes.  
* **Minimización de datos:** procesar solo la información estrictamente necesaria para los fines declarados.  
* **Responsabilidad y documentación:** mantener registros detallados de las actividades de tratamiento y, cuando corresponda, designar un Delegado de Protección de Datos (DPO).

[WARNING]
====

El incumplimiento del GDPR puede acarrear sanciones severas, de hasta 20 millones de euros o el 4 % de la facturación anual global, además de un daño reputacional considerable.  

Por ello, el cumplimiento de esta regulación se considera una práctica esencial en el diseño y operación de APIs que gestionen información personal o sensible.
====

===== Consideraciones del GDPR aplicadas a la seguridad de APIs

Para alinear el diseño de APIs REST con los principios del GDPR, se recomiendan las siguientes buenas prácticas:

* **Minimización de datos:** limitar los datos transmitidos a lo estrictamente necesario.  
* **Gestión del consentimiento:** implementar mecanismos para obtener, registrar y revocar el consentimiento de los usuarios.  
* **Cifrado:** proteger la información personal mediante cifrado de extremo a extremo en tránsito y en reposo.  
* **Control de acceso:** restringir el uso de las APIs únicamente a usuarios o sistemas autenticados y autorizados.  
* **Derechos de los interesados:** habilitar endpoints que permitan ejercer derechos como acceso, rectificación o eliminación de datos.  
* **Evaluaciones de impacto (DPIA):** analizar riesgos asociados al tratamiento de datos personales mediante APIs.  
* **Acuerdos de procesamiento de datos:** definir responsabilidades y obligaciones contractuales entre las partes que procesan datos.  
* **Notificación de brechas:** establecer procedimientos para detectar, registrar y notificar incidentes de seguridad.  
* **Transferencias internacionales:** garantizar que los datos transferidos fuera del Espacio Económico Europeo cuenten con mecanismos adecuados de protección.  
* **Gestión de proveedores:** verificar que los terceros o servicios de API cumplan también con los requisitos del GDPR.  
* **Transparencia y documentación:** mantener información clara sobre el uso y tratamiento de los datos a través de las APIs.  
* **Capacitación y sensibilización:** formar a los equipos de desarrollo y operación sobre los principios de privacidad y protección de datos.

[TIP]
====
La integración de estas consideraciones en el ciclo de vida de las APIs refuerza la confianza de los usuarios y contribuye al cumplimiento normativo, alineándose con el enfoque de seguridad desde el diseño.
====

==== Regulaciones legales relacionadas con la seguridad en APIs

Además de los estándares técnicos, existen regulaciones legales que establecen requisitos específicos para la protección de datos y la ciberseguridad. Estas regulaciones suelen exigir la implementación de medidas que prevengan el acceso no autorizado, la divulgación indebida o el uso inapropiado de la información.  

Entre las más relevantes se encuentran la Health Insurance Portability and Accountability Act (HIPAA) en Estados Unidos y la Cybersecurity Law de la República Popular de China, que obligan a las organizaciones a implementar controles de seguridad y reportar incidentes relacionados con la protección de datos y sistemas (U.S. Department of Health & Human Services, 2023; National People’s Congress, 2017).

===== HIPAA (Health Insurance Portability and Accountability Act)

La HIPAA es una regulación estadounidense que establece estándares para la protección de la información médica sensible, conocida como Protected Health Information (PHI). Su objetivo es garantizar la confidencialidad, integridad y disponibilidad de la PHI, al mismo tiempo que facilita la portabilidad del seguro médico y la eficiencia del sistema de salud (U.S. Department of Health & Human Services, 2023).

Uno de los pilares de la HIPAA es la Privacy Rule, que otorga a los pacientes derechos sobre su información médica, incluyendo el acceso, modificación y obtención de registros de uso. Por su parte, la Security Rule define salvaguardas administrativas, físicas y técnicas que las entidades deben aplicar para proteger la PHI electrónica (ePHI), tales como controles de acceso, cifrado, auditorías y planes de contingencia.

Asimismo, la HIPAA requiere que las entidades cubiertas establezcan acuerdos con sus asociados comerciales para asegurar el cumplimiento de las normas de privacidad y seguridad, siendo ambos responsables ante las autoridades reguladoras.

[WARNING]
====
El incumplimiento de la HIPAA puede derivar en sanciones económicas severas, además de planes obligatorios de acción correctiva supervisados por la Office for Civil Rights (OCR) del U.S. Department of Health & Human Services.
====

===== Consideraciones de la HIPAA en el diseño de APIs

Al desarrollar o integrar APIs que manejen información médica o datos sensibles, deben observarse los siguientes principios para cumplir con la HIPAA:

* **Cifrado de datos:** Utilizar protocolos como TLS para proteger la transmisión de datos.  
* **Control de acceso:** Implementar mecanismos de autenticación y autorización (por ejemplo, OAuth 2.0).  
* **Registros de auditoría:** Mantener trazabilidad de accesos y transacciones realizadas mediante la API.  
* **Minimización de datos:** Limitar la transmisión y exposición de PHI únicamente a lo necesario.  
* **Comunicación segura:** Emplear canales protegidos para evitar interceptaciones o alteraciones.  
* **Verificación de autorización:** Comprobar permisos en cada endpoint antes de exponer recursos.  
* **Almacenamiento seguro:** Proteger los datos almacenados mediante cifrado y controles de acceso.  
* **Documentación de cumplimiento:** Registrar políticas, controles y medidas de seguridad adoptadas.  

[TIP]
====
La HIPAA es especialmente relevante en APIs del sector salud o aquellas que gestionen información personal sensible.  
Aunque su aplicación es obligatoria solo en Estados Unidos, sus principios pueden servir como guía de buenas prácticas internacionales.
====
=== Modelado de amenazas

El modelado de amenazas es un enfoque de seguridad proactivo y estructurado que se utiliza para identificar, evaluar y mitigar posibles riesgos dentro de la arquitectura de un sistema antes de que puedan ser explotados. Permite visualizar cómo un atacante podría aprovechar vulnerabilidades mediante la identificación de activos críticos, como datos sensibles; la evaluación de vectores de ataque; el análisis de posibles actores de amenaza; y la definición de estrategias de mitigación para cada riesgo.

Como práctica clave, garantiza que las consideraciones de seguridad se integren desde las etapas iniciales de diseño hasta la implementación y operación, en consonancia con los principios de Shift Left y Secure by Design. Al anticipar vulnerabilidades de forma temprana, ayuda a tomar decisiones de diseño informadas, reducir costos de retrabajo y fomentar la creación de sistemas inherentemente seguros.

==== Importancia del modelado de amenazas

Pero ¿por qué deberíamos realizar el modelado de amenazas?  
El Manifiesto de Modelado de Amenazas señala que este proceso permite reconocer lo que puede salir mal en un sistema. Además, ayuda a identificar problemas de diseño e implementación que requieren mitigación, ya sea desde el inicio o a lo largo de la vida útil del sistema.  
El resultado de este análisis —las amenazas— sirve como insumo clave para guiar las decisiones en las fases posteriores de diseño, desarrollo, pruebas y mantenimiento (Threat Modeling Manifesto, 2020).

==== Propósito del modelado de amenazas

El principal objetivo del modelado de amenazas es proporcionar un marco sistemático que permita identificar, comprender, priorizar y mitigar posibles riesgos (Green, 2022).  
A través de este enfoque, las organizaciones pueden anticipar cómo los atacantes podrían explotar debilidades, entender las motivaciones y capacidades de los actores de amenaza, y establecer estrategias de defensa adecuadas (Green, 2022).

* **Identificar:** Descubrir posibles amenazas, vulnerabilidades y debilidades en el sistema o aplicación (Green, 2022).  
* **Comprender:** Analizar cómo estas amenazas pueden afectar el sistema, incluyendo las motivaciones, capacidades y posibles vectores de ataque (Green, 2022).  
* **Priorizar:** Evaluar y clasificar las amenazas identificadas según su gravedad, probabilidad de ocurrencia e impacto potencial (Green, 2022).  
* **Mitigar:** Desarrollar e implementar estrategias para reducir o eliminar los riesgos detectados, lo cual puede implicar rediseñar componentes, fortalecer defensas o establecer mecanismos de monitoreo y respuesta (Green, 2022).

==== Cuándo realizar el modelado de amenazas

El modelado de amenazas debe integrarse como parte del ciclo de vida del desarrollo de software (SDLC), preferentemente desde las fases tempranas de diseño o definición de requisitos (Green, 2022).  
Esto permite detectar vulnerabilidades potenciales antes de que se vuelvan costosas o difíciles de corregir.  

Sin embargo, también se recomienda revisarlo y actualizarlo cuando se presenten cambios significativos en la arquitectura, se descubran nuevas amenazas o el sistema migre a una infraestructura diferente (Green, 2022).

==== Elementos fundamentales del modelado de amenazas

El proceso de modelado de amenazas abarca varios componentes esenciales (Green, 2022):

* **Activos:** Representan los elementos valiosos que requieren protección, como datos sensibles, propiedad intelectual, funcionalidades críticas o la privacidad del usuario.  
* **Actores de amenaza:** Son individuos o grupos que podrían intentar explotar vulnerabilidades del sistema, como cibercriminales, hacktivistas, actores estatales o amenazas internas.  
* **Amenazas:** Acciones o eventos potencialmente negativos que podrían comprometer un activo, como brechas de datos, ataques DoS o campañas de phishing.  
* **Vulnerabilidades:** Debilidades o fallos en el diseño, implementación o configuración del sistema que pueden ser explotados.  
* **Vectores de ataque:** Rutas o métodos empleados por un atacante para obtener acceso o explotar una vulnerabilidad, como correos de phishing, puertos abiertos o bibliotecas comprometidas.  
* **Contramedidas:** Controles o mecanismos implementados para mitigar o eliminar las amenazas identificadas, que pueden ser técnicos (cifrado, autenticación), procedimentales (políticas de seguridad, capacitación) o físicos (acceso restringido a servidores).

[TIP]
====
El modelado de amenazas debe verse como un proceso iterativo y vivo: se adapta con el sistema, sus usuarios y su entorno.  
Actualizarlo regularmente es una práctica esencial para mantener la resiliencia y la seguridad de los sistemas frente a nuevas amenazas (Green, 2022).
====

==== Proceso de modelado de amenazas
De igual forma, OWASP menciona que el proceso de modelado de amenazas se puede descomponer en cuatro pasos de alto nivel.  
Cada paso se documenta a medida que se lleva a cabo. Esto nos da como resultado un documento, el cual es el modelado de amenazas para la aplicación.  
Se debe tener en cuenta que el trabajo de modelado de amenazas y el trabajo de crear documentos de modelado de amenazas son distintos (OWASP, s.f.).

Los cuatro pasos propuestos por OWASP son:

1. Paso 1: Alcance de su trabajo.  
2. Paso 2: Determinar las amenazas.  
3. Paso 3: Determinar las contramedidas y la mitigación.  
4. Paso 4: Evaluar su trabajo.  

===== Paso 1: Alcance de su trabajo

A este primer paso también se le conoce como “descomponer la aplicación”, el cual es un enfoque que se utiliza para realizar una revisión del modelo de amenazas o de la arquitectura. Este paso se refiere a entender la manera en la que funciona el sistema.  
Para ello, se deben seguir los siguientes puntos:

* Dibujar diagramas.  
* Identificar puntos de entrada.  
* Identificar activos.  
* Identificar los niveles de confianza.  
* Leer o crear historias de usuario.

Esta descomposición se lleva a cabo realizando *diagramas de flujo de datos (DFD)* con la información obtenida a partir de los pasos anteriores. Estos diagramas muestran las diferentes rutas a través del sistema, resaltando los límites de privilegios o confianzas.

===== Paso 2: Determinar las amenazas

Este paso es una actividad de investigación para encontrar las principales amenazas que pueden dañar el sistema.  
Para poder identificarlas es fundamental utilizar una metodología de categorización, como STRIDE, PASTA, VAST o SQUARE (OWASP, s.f.; Green, 2022).  

====== Metodología STRIDE

La metodología **STRIDE** fue desarrollada por Microsoft y es una de las más utilizadas para modelar amenazas.  
Su nombre proviene del acrónimo de seis categorías de amenazas, que ayudan a los diseñadores a pensar como un atacante e identificar debilidades específicas (Green, 2022):


|===
| Categoría | Descripción | Ejemplo de ataque | Contramedida típica

| **S**poofing (Suplantación de identidad)
| Ocurre cuando un atacante se hace pasar por alguien o algo que no es para obtener acceso no autorizado a los recursos.
| Robo de credenciales de inicio de sesión para suplantar a un usuario legítimo o la creación de un sitio web falso que engaña a las víctimas para que revelen información confidencial.
| Autenticación fuerte, MFA, validación de identidad.

| **T**ampering (Manipulación de datos)
| Modificación no autorizada de datos, ya sea en tránsito o en reposo.
| Interceptar y modificar las comunicaciones entre sistemas o alterar datos almacenados.
| Cifrado de datos, uso de hash en archivos y datos, controles de acceso robustos para garantizar la integridad de los datos.

| **R**epudiation (Repudio)
| Un usuario niega haber realizado una acción y el sistema carece de la capacidad de demostrar lo contrario.
| Un usuario niega haber realizado una transacción financiera.
| Auditoría, bitácoras de eventos, firmas digitales y uso de frameworks de logging.

| **I**nformation Disclosure (Divulgación de información)
| Fuga de datos confidenciales hacia partes no autorizadas.
| Puede manifestarse cuando los atacantes espían las comunicaciones de la red, acceden a archivos no protegidos o aprovechan vulnerabilidades para obtener acceso no autorizado a los datos.
| Cifrado de datos, control de acceso, procesos de clasificación y manejo de datos.

| **D**enial of Service (Denegación de servicio)
| Su objetivo es hacer que un sistema o servicio no esté disponible para sus usuarios previstos.
| Saturación con tráfico excesivo o explotación de vulnerabilidades para provocar su caída.
| Limitación de tasa (rate limiting), uso de WAF, diseñar sistemas con capacidad de redundancia y recuperación ante fallos.

| **E**levation of Privilege (Elevación de privilegios)
| Un atacante obtiene permisos superiores a los que debería tener, lo que le permite realizar acciones no autorizadas.
| Usuario aprovecha una vulnerabilidad para obtener privilegios administrativos podría tener acceso sin restricciones a datos confidenciales o funciones críticas del sistema.
| Principio del mínimo privilegio, auditorías periodicas de privilegios y corrección de vulnerabilidades.
|===

====== Ventajas de STRIDE

Una de las ventajas más significativas del modelo STRIDE es su simplicidad y versatilidad, lo que lo hace aplicable a una amplia variedad de sistemas y servicios. Los equipos de seguridad y los desarrolladores pueden utilizar STRIDE para realizar análisis de amenazas de manera sistemática durante la fase de diseño, ayudándoles a comprender y anticipar posibles riesgos.  
Al categorizar las amenazas mediante STRIDE, los arquitectos de seguridad pueden asegurar una evaluación integral de las preocupaciones de seguridad, abordando desde los mecanismos de autenticación hasta la integridad y disponibilidad de los datos (Green, 2022).

====== Uso de STRIDE en el modelado de amenazas

En la práctica, el modelado de amenazas utilizando STRIDE normalmente comienza con la comprensión de la arquitectura del sistema que se está analizando.  
Los profesionales de seguridad elaboran diagramas de flujo de datos (DFD) para visualizar cómo fluye la información a través del sistema, identificando componentes clave como almacenes de datos, procesos y canales de comunicación.  
Cada elemento del DFD se evalúa luego empleando el modelo STRIDE para identificar amenazas potenciales.  

[TIP]
====
El uso del modelo STRIDE permite a los equipos de seguridad comprender y anticipar los riesgos de manera estructurada.  
Su aplicación facilita una evaluación holística de los problemas de seguridad y fomenta la integración temprana de controles de protección durante la fase de diseño (Green, 2022).
====

===== Paso 3: Determinar las contramedidas y la mitigación

Después de haber identificado las amenazas, se deben definir las contramedidas adecuadas para mitigar los riesgos y evitar que el sistema se vea comprometido.  

Una vulnerabilidad puede mitigarse mediante la implementación de una contramedida. Dichas contramedidas se pueden identificar mediante listas de asignación de amenazas-contramedidas.  
Los factores que se incluyen en esta selección son la probabilidad de ataque, el daño potencial y el costo o complejidad de la mitigación (OWASP, s.f.).  

Las opciones para abordar el riesgo incluyen:

* **Aceptar:** el impacto es aceptable.  
* **Eliminar:** se eliminan los componentes que originan la vulnerabilidad.  
* **Mitigar:** se agregan controles o comprobaciones que reduzcan el impacto.  
* **Transferir:** el riesgo se transfiere a un tercero (aseguradora, cliente, etc.).

===== Paso 4: Evaluar su trabajo

Al concluir cualquier proyecto o tarea, es crucial hacerse una pregunta fundamental: ¿hicimos un trabajo lo suficientemente bueno?  
Este paso implica realizar una actividad retrospectiva, analizando de manera detallada y honesta la calidad de los resultados y la viabilidad de las soluciones implementadas.  
Este proceso de revisión fomenta la mejora continua en la práctica del modelado de amenazas (OWASP, s.f.).


===== Ejemplo práctico

A continuación, se presenta un ejemplo simplificado de modelado de amenazas utilizando la metodología STRIDE para una API REST del área de la salud que maneja datos de pacientes, permite el acceso a historiales médicos y facilita la programación de citas médicas.
Existen diversas herramientas que pueden ayudar a documentar el moodelado de amenazas, como las siguientes:

* OWASP Threat Dragon
* Microsoft Threat Modeling Tool
* IriusRisk
* ThreatModeler
* SecuriCAD

==== Paso 1 — Alcance del trabajo

En esta etapa se define el alcance del sistema y se descompone la aplicación para entender su funcionamiento general.  
El sistema analizado se compone de los siguientes elementos principales:

Nombre del sistema: **HealthAPI**
Versión: 1.0
Descripción: API REST para la gestión de datos de pacientes, historiales médicos y citas en una clínica.
Propietario del documento: Propietario del documento de modelado de amenazas
Participantes: Nombres de los involucrados en el modelado de amenazas
Revisor: Nombre del revisor del documento
Fecha de creación: Fecha de creación del documento

Dependencias externas: Suelen ser elementos externos al código de la aplicación y que representan una amenaza potencial.

TODO: Tabla en donde se documenten las dependencias externas del sistema con ID y descripción.

Puntos de entrada: Son los lugares donde un atacante puede interactuar con el sistema.
TODO: Tabla en donde se documenten los puntos de entrada del sistema con ID, nombre, descripción y nivel de confianza.

Puntos de salida: Son los lugares donde el sistema envía datos o respuestas a los usuarios o sistemas externos.

TODO: Tabla en donde se documenten los puntos de salida del sistema con ID, nombre, descripción y nivel de confianza.

Activos: Son los elementos valiosos que requieren protección, como datos sensibles, propiedad intelectual, funcionalidades críticas o la privacidad del usuario.
TODO: Tabla en donde se documenten los activos del sistema con ID, nombre, descripción y nivel de importancia.

Niveles de confianza: Se identifican los diferentes niveles de confianza dentro del sistema, como usuarios autenticados, administradores, servicios internos y externos.
TODO: Tabla en donde se documenten los niveles de confianza del sistema con ID, nombre y descripción.

Diagramas de flujo de datos (DFD)
TODO: Explicar sobre el DFD y su importancia en el modelado de amenazas.

TODO: Mostrar diagrama DFD del ejemplo.


==== Paso 2 — Determinar las amenazas (Aplicación de STRIDE)

Con base en la descomposición anterior, se analizan las amenazas aplicando las categorías de STRIDE sobre los componentes más relevantes.

TODO: Explicar cómo se identificaron las amenazas, en este caso se siguió STRIDE y ya está más o menos explicado qué pasa en cada categoria, después es necesario analizar las amenazas para determinar el riesgo (explicar cómo sacar el riesgo) (Para cada elemento del DFD se analizan las posibles amenazas aplicando STRIDE), aplicar el arbol de amenazas. Entonces ya se presentan las amenazas identificadas en una tabla con el elemento (del DFD, por ejemplo un web response que es un flujo de datos), el riesgo, lla categoria de stride, amenaza, descripcion.

[cols="1,2,2,2"]
|===
| Recurso | Amenaza (STRIDE) | Ejemplo de escenario | Contramedida propuesta

| `POST /auth/login`
| **Spoofing**
| Un atacante usa credenciales robadas para autenticarse como un paciente.
| Implementar autenticación multifactor (MFA), limitar intentos de inicio de sesión y registrar patrones de acceso sospechosos.

| `GET /patients/{id}`
| **Information Disclosure**
| Un usuario con token válido accede a información de otro paciente mediante un ID manipulado.
| Verificar el propietario del recurso, aplicar controles de acceso a nivel de campo y cifrar la información sensible.

| `POST /appointments`
| **Tampering**
| Modificación del contenido de una solicitud para cambiar la fecha o el costo de una cita.
| Usar HTTPS, validar datos del lado del servidor y firmar los mensajes si se requiere integridad adicional.

| `GET /records`
| **Denial of Service (DoS)**
| Solicitudes masivas a los historiales médicos que saturan el servidor.
| Implementar *rate limiting*, caching y estrategias de escalado.

| `PUT /patients/{id}`
| **Elevation of Privilege**
| Un usuario estándar intenta modificar información administrativa.
| Aplicar controles RBAC y validar los privilegios en cada solicitud.

|===

[TIP]
====
Aplicar STRIDE sobre los componentes del sistema permite identificar amenazas específicas y asignar contramedidas claras desde las primeras etapas del diseño.
====

==== Paso 3 — Determinar contramedidas y mitigación

Una vez identificadas las amenazas, se definen las contramedidas apropiadas.

TODO: Explicar que a veces como ya están categorizadas con STRIDE, ya se pueden ir pensando en las contramedidas típicas de cada categoría. Y finalmente se pueden derivar amenazas no mitigadas, parciales o mitigadas.

Por ejemplo:

* **Spoofing:** aplicar autenticación fuerte, MFA y validación de tokens.  
* **Tampering:** cifrar datos en tránsito y validar integridad.  
* **Repudiation:** habilitar registro de auditoría con trazabilidad.  
* **Information Disclosure:** implementar controles de acceso y clasificación de datos.  
* **Denial of Service:** limitar la tasa de peticiones y usar sistemas de detección de anomalías.  
* **Elevation of Privilege:** revisar roles, permisos y aplicar el principio de mínimo privilegio.

Estas contramedidas se documentan junto con la justificación de su elección, considerando el costo, el impacto y la probabilidad del ataque.

TODO: Ahora sí se podrían incluir las contramedidas en la tabla del Paso 2. 

TODO: Una vez que se tienen esselementos, se puede crear el modelo con una herramienta como OWASP Threat Dragon o Microsoft Threat Modeling Tool. En nuestro caso, se usará OWASP Threat Dragon así que hay que incluir capturas.

==== Paso 4 — Evaluar el trabajo

Finalmente, se realiza una evaluación del modelo de amenazas y las mitigaciones propuestas:

* Verificar si se han cubierto todos los componentes y flujos críticos.
* Revisar la coherencia entre las amenazas identificadas y las contramedidas aplicadas.
* Comprobar que las medidas propuestas son viables técnica y económicamente.
* Planificar revisiones periódicas del modelo conforme evolucione la arquitectura del sistema.


[TIP]
====
El modelo de amenazas debe mantenerse como un artefacto vivo que se actualice junto con los cambios de diseño. Su revisión periódica permite detectar nuevos riesgos antes de la fase de implementación.
====


=== Requisitos funcionales

=== Requisitos de seguridad asociados

=== Validación y trazabilidad de requisitos


